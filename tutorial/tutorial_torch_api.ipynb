{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA-IQ TUTORIAL: PYTORCH STYLE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ER17PSHfGat"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_data import load_adult_data\n",
    "from data_iq.dataiq_class import DataIQ_Torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get demo public dataset: Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "X_train, X_test, y_train, y_test, X, y = load_adult_data(split_size=0.3)\n",
    "\n",
    "# Pre-processing & normalization\n",
    "X_train = X_train.to_numpy().astype(np.float32)\n",
    "y_train = y_train.values.astype(np.float32)\n",
    "X_test = X_test.to_numpy().astype(np.float32)\n",
    "y_test = y_test.values.astype(np.float32)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data ready for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data = TrainData(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTIALIZE TORCH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Example_NN(nn.Module):\n",
    "    def __init__(self, input_size=12, num_units=64, nonlin=F.relu, nlabels=2):\n",
    "        super(Example_NN, self).__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(input_size, num_units)\n",
    "        self.dense1 = nn.Linear(num_units, 32)\n",
    "        self.dense2 = nn.Linear(32, 16)\n",
    "        self.dense3 = nn.Linear(16, 8)\n",
    "        self.nonlin = nonlin\n",
    "        self.output = nn.Linear(8, nlabels)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.relu(self.dense2(X))\n",
    "        X = F.relu(self.dense3(X))\n",
    "        X = F.softmax(self.output(X))\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 10\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Init model\n",
    "net = Example_NN(input_size=X_train.shape[1], nlabels=len(np.unique(y_train)))\n",
    "net.to(device)\n",
    "\n",
    "n_feats = X_train.shape[1]\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=128, shuffle=True)\n",
    "sf = nn.LogSoftmax()\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALIZE DATA-IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiq = DataIQ_Torch(X=X_train, y=y_train, sparse_labels=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN LOOP: CALL DATA-IQ AT THE END OF EVERY EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqbpXIbeInMx",
    "outputId": "31d5db9c-669c-4388-a8a0-c3f2251d5f0e"
   },
   "outputs": [],
   "source": [
    "for e in range(1, EPOCHS + 1):\n",
    "    net.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = net(X_batch)\n",
    "        _, predicted = torch.max(y_pred.data, 1)\n",
    "\n",
    "        y_batch = y_batch.to(torch.int64)\n",
    "\n",
    "        loss = criterion(sf(y_pred), y_batch)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += (predicted == y_batch).sum().item() / len(y_batch)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Acc: {epoch_acc/len(train_loader):.3f}\"\n",
    "    )\n",
    "\n",
    "    ################################################################################################\n",
    "    #\n",
    "    # CALL DATA-IQ on EPOCH END\n",
    "    #\n",
    "    ################################################################################################\n",
    "    dataiq.on_epoch_end(net, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCESS METRICS\n",
    "\n",
    "#### Aleatoric uncertainty via: `dataiq.aleatoric`\n",
    "#### Variability via: `dataiq.variability`\n",
    "#### Predictive confidence via: `dataiq.confidence`\n",
    "#### Entropy via: `dataiq.entropy`\n",
    "#### Mutual information via: `dataiq.mi`\n",
    "#### Correctness over training via: `dataiq.correctness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleatoric_uncertainty = dataiq.aleatoric\n",
    "confidence = dataiq.confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT DATA-IQ Characteristic curve:\n",
    "### X-AXIS: ALEATORIC UNCERTAINTY\n",
    "### Y-AXIS: PREDICTIVE CONFIDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "FBnp-DA9QUC2",
    "outputId": "453cc8a4-b91d-46fc-d1f4-aa31a5445cf4"
   },
   "outputs": [],
   "source": [
    "plt.style.reload_library()\n",
    "plt.style.use([\"science\", \"ieee\", \"no-latex\", \"notebook\", \"grid\", \"vibrant\"])\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 50\n",
    "BIGGER_SIZE = 50\n",
    "\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=14)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=14)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=14)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=14)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# DATA-IQ\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "aleatoric_uncertainty = dataiq.aleatoric\n",
    "confidence = dataiq.confidence\n",
    "\n",
    "sns.scatterplot(x=aleatoric_uncertainty, y=confidence, color=\"b\", label=\"NN\")\n",
    "\n",
    "plt.title(\"Data-IQ\")\n",
    "plt.xlabel(\"Aleatoric Uncertainty\")\n",
    "plt.ylabel(\"Confidence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO STRATIFY SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE THRESHOLDS: THESE CAN BE ADAPTED PER USE-CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_thresh = 50\n",
    "thresh = 0.25\n",
    "conf_thresh_low = thresh\n",
    "conf_thresh_high = 1 - thresh\n",
    "conf_thresh = 0.5\n",
    "\n",
    "hard_train = np.where(\n",
    "    (confidence <= conf_thresh_low)\n",
    "    & (aleatoric_uncertainty <= np.percentile(aleatoric_uncertainty, percentile_thresh))\n",
    ")[0]\n",
    "easy_train = np.where(\n",
    "    (confidence >= conf_thresh_high)\n",
    "    & (aleatoric_uncertainty <= np.percentile(aleatoric_uncertainty, percentile_thresh))\n",
    ")[0]\n",
    "\n",
    "hard_easy = np.concatenate((hard_train, easy_train))\n",
    "ambig_train = []\n",
    "for id in range(len(confidence)):\n",
    "    if id not in hard_easy:\n",
    "        ambig_train.append(id)\n",
    "\n",
    "ambig_train = np.array(ambig_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(easy_train), len(ambig_train), len(hard_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
