{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA-IQ TUTORIAL: SKLEARN STYLE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ER17PSHfGat"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from demo_data import load_adult_data\n",
    "from data_iq.dataiq_class import DataIQ_SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get demo public dataset: Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X, y = load_adult_data(split_size=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT XGBOOST & then access Data-IQ each per fit iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZE DATA-IQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiq_xgb = DataIQ_SKLearn(X=X_train, y=y_train.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqbpXIbeInMx",
    "outputId": "31d5db9c-669c-4388-a8a0-c3f2251d5f0e"
   },
   "outputs": [],
   "source": [
    "nest = 10\n",
    "clf = xgb.XGBClassifier(n_estimators=nest)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "for i in range(1, nest):\n",
    "    dataiq_xgb.on_epoch_end(clf=clf, iteration=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXAMPLE WITH LIGHGBM\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "\n",
    "# # nest = 10\n",
    "# # TRAIN LIGHTGBM\n",
    "# clf = LGBMClassifier(n_estimators=nest)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# # Compute GBM Data-IQ\n",
    "# dataiq_gbm = DataIQ_SKLearn(X=X_train, y=y_train)\n",
    "# for i in range(1,nest):\n",
    "#   dataiq_gbm.on_epoch_end(clf=clf, iteration=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE WITH CATBOOST\n",
    "\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# TRAIN CATBOOST\n",
    "# clf = CatBoostClassifier(n_estimators=nest)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# Compute Catbosot Data-IQ: Note the catboost=True\n",
    "# dataiq_catboost = DataIQ_SKLearn(X=X_train, y=y_train, catboost=True)\n",
    "# for i in range(1,nest):\n",
    "#   dataiq_catboost.on_epoch_end(clf=clf, iteration=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCESS METRICS\n",
    "\n",
    "#### Aleatoric uncertainty via: `dataiq.aleatoric`\n",
    "#### Variability via: `dataiq.variability`\n",
    "#### Predictive confidence via: `dataiq.confidence`\n",
    "#### Entropy via: `dataiq.entropy`\n",
    "#### Mutual information via: `dataiq.mi`\n",
    "#### Correctness over training via: `dataiq.correctness`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aleatoric_uncertainty = dataiq_xgb.aleatoric\n",
    "confidence = dataiq_xgb.confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT DATA-IQ Characteristic curve:\n",
    "### X-AXIS: ALEATORIC UNCERTAINTY\n",
    "### Y-AXIS: PREDICTIVE CONFIDENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "FBnp-DA9QUC2",
    "outputId": "453cc8a4-b91d-46fc-d1f4-aa31a5445cf4"
   },
   "outputs": [],
   "source": [
    "plt.style.reload_library()\n",
    "plt.style.use([\"science\", \"ieee\", \"no-latex\", \"notebook\", \"grid\", \"vibrant\"])\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 50\n",
    "BIGGER_SIZE = 50\n",
    "\n",
    "plt.rc(\"font\", size=SMALL_SIZE)  # controls default text sizes\n",
    "plt.rc(\"axes\", titlesize=SMALL_SIZE)  # fontsize of the axes title\n",
    "plt.rc(\"axes\", labelsize=14)  # fontsize of the x and y labels\n",
    "plt.rc(\"xtick\", labelsize=14)  # fontsize of the tick labels\n",
    "plt.rc(\"ytick\", labelsize=14)  # fontsize of the tick labels\n",
    "plt.rc(\"legend\", fontsize=14)  # legend fontsize\n",
    "plt.rc(\"figure\", titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "# DATA-IQ\n",
    "plt.figure(figsize=(5, 3))\n",
    "\n",
    "\n",
    "sns.scatterplot(x=aleatoric_uncertainty, y=confidence, color=\"b\", label=\"Data-IQ Curve\")\n",
    "\n",
    "plt.title(\"Data-IQ\")\n",
    "plt.xlabel(\"Aleatoric Uncertainty\")\n",
    "plt.ylabel(\"Confidence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO STRATIFY SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE THRESHOLDS: THESE CAN BE ADAPTED PER USE-CASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentile_thresh = 50\n",
    "thresh = 0.25\n",
    "conf_thresh_low = thresh\n",
    "conf_thresh_high = 1 - thresh\n",
    "conf_thresh = 0.5\n",
    "\n",
    "hard_train = np.where(\n",
    "    (confidence <= conf_thresh_low)\n",
    "    & (aleatoric_uncertainty <= np.percentile(aleatoric_uncertainty, percentile_thresh))\n",
    ")[0]\n",
    "easy_train = np.where(\n",
    "    (confidence >= conf_thresh_high)\n",
    "    & (aleatoric_uncertainty <= np.percentile(aleatoric_uncertainty, percentile_thresh))\n",
    ")[0]\n",
    "\n",
    "hard_easy = np.concatenate((hard_train, easy_train))\n",
    "ambig_train = []\n",
    "for id in range(len(confidence)):\n",
    "    if id not in hard_easy:\n",
    "        ambig_train.append(id)\n",
    "\n",
    "ambig_train = np.array(ambig_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(easy_train), len(ambig_train), len(hard_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
